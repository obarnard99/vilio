Some weights of BertOPretraining were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['bert.img_embedding.weight', 'bert.img_embedding.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/1136 [00:00<?, ?it/s]pretrain
Load 9092 data from split(s) pretrain.
Start to load Faster-RCNN detected objects from /home/miproj/4thyr.oct2020/ojrb2/vilio/data/features/tsv/5.tsv
Loaded 9092 images in file /home/miproj/4thyr.oct2020/ojrb2/vilio/data/features/tsv/5.tsv in 12 seconds.
Use 9092 data in torch dataset


Load pre-trained model from /home/miproj/4thyr.oct2020/ojrb2/vilio/data/models/pytorch_model.bin
MODIFYING: bert.img_embedding.weight

Weights in loaded but not in model:

Weights in model but not in loaded:
bert.embeddings.position_ids

Batch per epoch: 1136
Total Iters: 9088
Warm up Iters: 454
  0%|          | 1/1136 [00:02<40:02,  2.12s/it]  0%|          | 1/1136 [00:02<43:06,  2.28s/it]
Traceback (most recent call last):
  File "pretrain_bertO.py", line 436, in <module>
    lxmert.train(train_tuple, valid_tuple)
  File "pretrain_bertO.py", line 356, in train
    loss, losses, logit = self.train_batch(optim, scheduler, batch)
  File "pretrain_bertO.py", line 309, in train_batch
    loss, losses, ans_logit = self.forward(batch)
  File "pretrain_bertO.py", line 263, in forward
    train_features = [convert_example_to_features(example, self.max_seq_length, self.tokenizer)
  File "pretrain_bertO.py", line 263, in <listcomp>
    train_features = [convert_example_to_features(example, self.max_seq_length, self.tokenizer)
  File "pretrain_bertO.py", line 190, in convert_example_to_features
    masked_feat, feat_mask = random_feat(feat)
  File "pretrain_bertO.py", line 131, in random_feat
    mask_feats[i, :] = train_tuple.torchdset.random_feat()
  File "/home/miproj/4thyr.oct2020/ojrb2/vilio/features/vilio/fts_tsv/hm_pretrain_data_tsv.py", line 94, in random_feat
    feat = img_info['features'][random.randint(0, 35)]
IndexError: index 13 is out of bounds for axis 0 with size 5
Some weights of BertO were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['bert.img_embedding.weight', 'bert.img_embedding.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Clean datasets already exist
Load 8592 data from split(s) trainlarge.
Start to load Faster-RCNN detected objects from /home/miproj/4thyr.oct2020/ojrb2/vilio/data/features/tsv/5.tsv
Loaded 8592 images in file /home/miproj/4thyr.oct2020/ojrb2/vilio/data/features/tsv/5.tsv in 8 seconds.
Use 8592 data in torch dataset

Load 500 data from split(s) dev_seen.
Start to load Faster-RCNN detected objects from /home/miproj/4thyr.oct2020/ojrb2/vilio/data/features/tsv/5.tsv
Loaded 500 images in file /home/miproj/4thyr.oct2020/ojrb2/vilio/data/features/tsv/5.tsv in 6 seconds.
Use 500 data in torch dataset

UNEXPECTED:  []
MISSING:  ['bert.img_embedding.weight', 'bert.img_embedding.bias']
ERRORS:  []
REINITING:  Linear(in_features=1024, out_features=2048, bias=True)
REINITING:  GeLU()
REINITING:  LayerNorm((2048,), eps=1e-12, elementwise_affine=True)
REINITING:  Linear(in_features=2048, out_features=2, bias=True)
REINITING:  Sequential(
  (0): Linear(in_features=1024, out_features=2048, bias=True)
  (1): GeLU()
  (2): LayerNorm((2048,), eps=1e-12, elementwise_affine=True)
  (3): Linear(in_features=2048, out_features=2, bias=True)
)
Load pre-trained model from /home/miproj/4thyr.oct2020/ojrb2/vilio/data/LAST_O5.pth
Traceback (most recent call last):
  File "hm.py", line 391, in <module>
    main()
  File "hm.py", line 346, in main
    hm = HM()
  File "hm.py", line 82, in __init__
    self.model.load(args.loadpre)
  File "/home/miproj/4thyr.oct2020/ojrb2/vilio/models/O.py", line 200, in load
    state_dict = torch.load("%s" % path)
  File "/home/miproj/4thyr.oct2020/ojrb2/miniconda3/envs/vilio/lib/python3.8/site-packages/torch/serialization.py", line 581, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/miproj/4thyr.oct2020/ojrb2/miniconda3/envs/vilio/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/miproj/4thyr.oct2020/ojrb2/miniconda3/envs/vilio/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/home/miproj/4thyr.oct2020/ojrb2/vilio/data/LAST_O5.pth'
Some weights of BertO were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['bert.img_embedding.weight', 'bert.img_embedding.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Clean datasets already exist
Load 8592 data from split(s) trainlarge.
Start to load Faster-RCNN detected objects from /home/miproj/4thyr.oct2020/ojrb2/vilio/data/features/tsv/5.tsv
Loaded 8592 images in file /home/miproj/4thyr.oct2020/ojrb2/vilio/data/features/tsv/5.tsv in 8 seconds.
Use 8592 data in torch dataset

Load 500 data from split(s) dev_seen.
Start to load Faster-RCNN detected objects from /home/miproj/4thyr.oct2020/ojrb2/vilio/data/features/tsv/5.tsv
Loaded 500 images in file /home/miproj/4thyr.oct2020/ojrb2/vilio/data/features/tsv/5.tsv in 6 seconds.
Use 500 data in torch dataset

UNEXPECTED:  []
MISSING:  ['bert.img_embedding.weight', 'bert.img_embedding.bias']
ERRORS:  []
REINITING:  Linear(in_features=1024, out_features=2048, bias=True)
REINITING:  GeLU()
REINITING:  LayerNorm((2048,), eps=1e-12, elementwise_affine=True)
REINITING:  Linear(in_features=2048, out_features=2, bias=True)
REINITING:  Sequential(
  (0): Linear(in_features=1024, out_features=2048, bias=True)
  (1): GeLU()
  (2): LayerNorm((2048,), eps=1e-12, elementwise_affine=True)
  (3): Linear(in_features=2048, out_features=2, bias=True)
)
Load pre-trained model from /home/miproj/4thyr.oct2020/ojrb2/vilio/data/LAST_O5.pth
Traceback (most recent call last):
  File "hm.py", line 391, in <module>
    main()
  File "hm.py", line 346, in main
    hm = HM()
  File "hm.py", line 82, in __init__
    self.model.load(args.loadpre)
  File "/home/miproj/4thyr.oct2020/ojrb2/vilio/models/O.py", line 200, in load
    state_dict = torch.load("%s" % path)
  File "/home/miproj/4thyr.oct2020/ojrb2/miniconda3/envs/vilio/lib/python3.8/site-packages/torch/serialization.py", line 581, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/miproj/4thyr.oct2020/ojrb2/miniconda3/envs/vilio/lib/python3.8/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/miproj/4thyr.oct2020/ojrb2/miniconda3/envs/vilio/lib/python3.8/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/home/miproj/4thyr.oct2020/ojrb2/vilio/data/LAST_O5.pth'
