{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "forty-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "from heapq import heappush, heappop, heappushpop\n",
    "\n",
    "import matplotlib.pyplot as plotter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "from utils.ens import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pretty-rehabilitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.width\", 180)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-childhood",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "floral-health",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/csvs'\n",
    "gt_path = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accessory-application",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data:\n",
      "O365050_dev_seen_SA.csv\n",
      "O365050_test_seen_SA.csv\n",
      "O365050_test_unseen_SA.csv\n",
      "U365072_dev_seen_SA.csv\n",
      "U365072_test_seen_SA.csv\n",
      "U365072_test_unseen_SA.csv\n",
      "VLMDB_dev_seen_SA.csv\n",
      "VLMDB_test_seen_SA.csv\n",
      "VLMDB_test_unseen_SA.csv\n"
     ]
    }
   ],
   "source": [
    "# Ground truth\n",
    "gt = pd.read_json(os.path.join(gt_path, 'dev_seen.jsonl'), lines=True)\n",
    "\n",
    "dev, ts, tu = {}, {}, {}\n",
    "print('Loading data:')\n",
    "for csv in sorted(os.listdir(path)):\n",
    "    if \".csv\" in csv:\n",
    "        print(csv)\n",
    "        name = csv.split('_')[0]\n",
    "        if (\"dev\" in csv) or (\"val\" in csv):\n",
    "            dev[name] = pd.read_csv(os.path.join(path, csv))\n",
    "            dev_idx = dev[name].id.values\n",
    "        elif \"test_unseen\" in csv:\n",
    "            tu[name] = pd.read_csv(os.path.join(path, csv))\n",
    "            tu_idx = tu[name].id.values\n",
    "        elif \"test_seen\" in csv:\n",
    "            ts[name] = pd.read_csv(os.path.join(path, csv))\n",
    "            ts_idx = ts[name].id.values\n",
    "\n",
    "dev_probas = pd.DataFrame({k: v.proba.values for k, v in dev.items()})\n",
    "#dev_probas.set_index(dev_idx, inplace=True)\n",
    "ts_probas = pd.DataFrame({k: v.proba.values for k, v in ts.items()})\n",
    "#test_seen_probas.set_index(ts_idx, inplace=True)\n",
    "tu_probas = pd.DataFrame({k: v.proba.values for k, v in tu.items()})\n",
    "#test_unseen_probas.set_index(tu_idx, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-apache",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vertical-margin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(data, weights=None):\n",
    "    N = data.shape[1]\n",
    "    if weights is None:\n",
    "        weights = [1/N] * N\n",
    "    elif np.sum(weights) != 1.:\n",
    "        weights = weights / np.sum(weights)\n",
    "    \n",
    "    # Compute weighted avg\n",
    "    return data.apply(lambda row: row.multiply(weights).sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "institutional-audio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_from_roc(labels, probas, splits=None):\n",
    "    '''Determines the greatest achievable accuracy from the ROC curve.'''\n",
    "    if splits is None:\n",
    "        splits = (250, 250)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(labels, probas)\n",
    "    tp = tpr * splits[0]\n",
    "    tn = (1 - fpr) * splits[1]\n",
    "    acc = (tp + tn) / np.sum(splits)\n",
    "    best_threshold = thresholds[np.argmax(acc)]\n",
    "\n",
    "    return np.amax(acc), best_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-fashion",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "otherwise-condition",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------- ROUND 0 ---------------------\n",
      "Individual AUROCs for Validation Sets:\n",
      "\n",
      "O365050 0.7678225664495687\n",
      "U365072 0.7847370021283063\n",
      "VLMDB 0.751900273639404\n",
      "\n",
      "--------------------------------------------------\n",
      "Spearman Corrs:\n",
      "\n",
      "           O365050   U365072     VLMDB\n",
      "O365050  1.000000  0.844154  0.739764\n",
      "U365072  0.844154  1.000000  0.733841\n",
      "VLMDB    0.739764  0.733841  1.000000\n",
      "\n",
      "           O365050   U365072     VLMDB\n",
      "O365050  1.000000  0.816988  0.788083\n",
      "U365072  0.816988  1.000000  0.740760\n",
      "VLMDB    0.788083  0.740760  1.000000\n",
      "\n",
      "           O365050   U365072     VLMDB\n",
      "O365050  1.000000  0.807346  0.761874\n",
      "U365072  0.807346  1.000000  0.718090\n",
      "VLMDB    0.761874  0.718090  1.000000\n",
      "\n",
      "--------------------------------------------------\n",
      "Simple:\n",
      "500\n",
      "Optimizing 3 inputs.\n",
      "Optimized = 0.7918100206429726\n",
      "Weights = [0.16097738 0.67080073 0.13244844]\n",
      "AUROC: 0.7918\n",
      "Accuracy: 0.7139\n",
      "\n",
      "--------------------------------------------------\n",
      "Arithmetic Mean:\n",
      "AUROC: 0.7723\n",
      "Accuracy: 0.6919\n",
      "\n",
      "--------------------------------------------------\n",
      "Geometric Mean:\n",
      "AUROC: 0.7888\n",
      "Accuracy: 0.7100\n",
      "\n",
      "--------------------------------------------------\n",
      "Rank Average:\n",
      "AUROC: 0.7887\n",
      "Accuracy: 0.7095\n",
      "\n",
      "--------------------------------------------------\n",
      "Currently at 0.7918100206429726 after 1 loops.\n",
      "\n",
      "--------------------- ROUND 1 ---------------------\n",
      "Individual AUROCs for Validation Sets:\n",
      "\n",
      "O365050 0.7678225664495687\n",
      "U365072 0.7847370021283063\n",
      "VLMDB 0.751900273639404\n",
      "dev_SX_0 0.7918100206429726\n",
      "dev_AM_0 0.7723192139668112\n",
      "dev_GM_0 0.7888495943415852\n",
      "dev_RA_0 0.7886575666896034\n",
      "\n",
      "--------------------------------------------------\n",
      "Dropped: VLMDB\n",
      "Dropped: O365050\n",
      "\n",
      "--------------------------------------------------\n",
      "Spearman Corrs:\n",
      "\n",
      "            U365072  dev_SX_0  dev_AM_0  dev_GM_0  dev_RA_0\n",
      "U365072   1.000000  0.965243  0.892908  0.925985  0.935893\n",
      "dev_SX_0  0.965243  1.000000  0.967050  0.989732  0.990621\n",
      "dev_AM_0  0.892908  0.967050  1.000000  0.982728  0.986221\n",
      "dev_GM_0  0.925985  0.989732  0.982728  1.000000  0.997340\n",
      "dev_RA_0  0.935893  0.990621  0.986221  0.997340  1.000000\n",
      "\n",
      "           U365072   ts_SX_0   ts_AM_0   ts_GM_0   ts_RA_0\n",
      "U365072  1.000000  0.968758  0.891400  0.930762  0.932205\n",
      "ts_SX_0  0.968758  1.000000  0.964775  0.989601  0.986753\n",
      "ts_AM_0  0.891400  0.964775  1.000000  0.985447  0.988064\n",
      "ts_GM_0  0.930762  0.989601  0.985447  1.000000  0.997385\n",
      "ts_RA_0  0.932205  0.986753  0.988064  0.997385  1.000000\n",
      "\n",
      "           U365072   tu_SX_0   tu_AM_0   tu_GM_0   tu_RA_0\n",
      "U365072  1.000000  0.970004  0.889726  0.926272  0.929555\n",
      "tu_SX_0  0.970004  1.000000  0.961881  0.987112  0.985137\n",
      "tu_AM_0  0.889726  0.961881  1.000000  0.983290  0.987356\n",
      "tu_GM_0  0.926272  0.987112  0.983290  1.000000  0.997364\n",
      "tu_RA_0  0.929555  0.985137  0.987356  0.997364  1.000000\n",
      "\n",
      "--------------------------------------------------\n",
      "Simple:\n",
      "500\n",
      "Optimizing 5 inputs.\n",
      "Optimized = 0.7918100206429726\n",
      "Weights = [0. 1. 0. 0. 0.]\n",
      "AUROC: 0.7918\n",
      "Accuracy: 0.7139\n",
      "\n",
      "--------------------------------------------------\n",
      "Arithmetic Mean:\n",
      "AUROC: 0.7849\n",
      "Accuracy: 0.7050\n",
      "\n",
      "--------------------------------------------------\n",
      "Geometric Mean:\n",
      "AUROC: 0.7914\n",
      "Accuracy: 0.7158\n",
      "\n",
      "--------------------------------------------------\n",
      "Rank Average:\n",
      "AUROC: 0.7895\n",
      "Accuracy: 0.7155\n",
      "\n",
      "--------------------------------------------------\n",
      "Currently at 0.7918100206429726 after 2 loops.\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "loop, last_score, delta = 0, 0, 0.1\n",
    "\n",
    "while delta > 0.0001:\n",
    "\n",
    "    # Individual AUROCs\n",
    "    print('\\n' + '-' * 21 , 'ROUND ' + str(loop) , '-' * 21)\n",
    "    print(\"Individual AUROCs for Validation Sets:\\n\")\n",
    "    for i, column in enumerate(dev_probas):   \n",
    "        score = roc_auc_score(gt.label, dev_probas.iloc[:, i])\n",
    "        print(column, score)\n",
    "\n",
    "    # Drop worst performing sets\n",
    "    if loop > 0:\n",
    "        print('\\n' + '-' * 50)\n",
    "        scores = dev_probas.apply(lambda col: roc_auc_score(gt.label, col), result_type='reduce')\n",
    "        while len(scores) > 5:\n",
    "            worst = scores.idxmin()\n",
    "            #del dev[worst]\n",
    "            dev_probas.drop(worst, axis=1, inplace=True)\n",
    "            ts_probas.drop(worst, axis=1, inplace=True)\n",
    "            tu_probas.drop(worst, axis=1, inplace=True)\n",
    "            scores.drop(worst, inplace=True)\n",
    "            print(\"Dropped:\", worst)\n",
    "\n",
    "    # Spearman Correlations:\n",
    "    print('\\n' + '-' * 50)\n",
    "    print(\"Spearman Corrs:\")\n",
    "    dev_corr = dev_probas.corr(method='spearman')\n",
    "    test_seen_corr = ts_probas.corr(method='spearman')\n",
    "    test_unseen_corr = tu_probas.corr(method='spearman')\n",
    "\n",
    "    print('\\n', dev_corr)\n",
    "    print('\\n', test_seen_corr)\n",
    "    print('\\n', test_unseen_corr)\n",
    "    print('\\n' + '-' * 50)\n",
    "\n",
    "    # Simple\n",
    "    print('Simple:')\n",
    "    weights_dev = Simplex(dev_probas, gt.label)\n",
    "    dev_probas[f'dev_SX_{loop}'] = average(dev_probas, weights=weights_dev)\n",
    "    ts_probas[f'ts_SX_{loop}'] = average(ts_probas, weights=weights_dev)\n",
    "    tu_probas[f'tu_SX_{loop}'] = average(tu_probas, weights=weights_dev)\n",
    "    score = roc_auc_score(gt.label, dev_probas[f'dev_SX_{loop}'])\n",
    "    print(f\"AUROC: {score:.4f}\")\n",
    "    print(f\"Accuracy: {acc_from_roc(gt.label, dev_probas[f'dev_SX_{loop}'])[0]:.4f}\")\n",
    "    print('\\n' + '-' * 50)\n",
    "    \n",
    "    # Arithmetic Mean\n",
    "    print('Arithmetic Mean:')\n",
    "    dev_probas[f'dev_AM_{loop}'] = average(dev_probas.apply(np.exp))\n",
    "    ts_probas[f'ts_AM_{loop}'] = average(ts_probas.apply(np.exp))\n",
    "    tu_probas[f'tu_AM_{loop}'] = average(tu_probas.apply(np.exp))\n",
    "    print(f\"AUROC: {roc_auc_score(gt.label, dev_probas[f'dev_AM_{loop}']):.4f}\")\n",
    "    print(f\"Accuracy: {acc_from_roc(gt.label, dev_probas[f'dev_AM_{loop}'])[0]:.4f}\")\n",
    "    print('\\n' + '-' * 50)\n",
    "    \n",
    "    # Geometric Mean (remain in logspace)\n",
    "    print('Geometric Mean:')\n",
    "    dev_probas[f'dev_GM_{loop}'] = average(dev_probas)\n",
    "    ts_probas[f'ts_GM_{loop}'] = average(ts_probas)\n",
    "    tu_probas[f'tu_GM_{loop}'] = average(tu_probas)\n",
    "    print(f\"AUROC: {roc_auc_score(gt.label, dev_probas[f'dev_GM_{loop}']):.4f}\")\n",
    "    print(f\"Accuracy: {acc_from_roc(gt.label, dev_probas[f'dev_GM_{loop}'])[0]:.4f}\")\n",
    "    print('\\n' + '-' * 50)\n",
    "\n",
    "    # TODO: Power Average\n",
    "    '''\n",
    "    print('Power Average:')\n",
    "    dev_PA = simple_average(dev_probas, dev[0], power=2, normalize=True)\n",
    "    test_PA = simple_average(test_probas, test[0], power=2, normalize=True)\n",
    "    test_unseen_PA = simple_average(test_unseen_probas, test_unseen[0], power=2, normalize=True)\n",
    "    print(roc_auc_score(dev_df.label, dev_PA.proba), accuracy_score(dev_df.label, dev_PA.label))\n",
    "    print('\\n' + '-' * 50)\n",
    "    '''\n",
    "    \n",
    "    # Rank Average\n",
    "    print('Rank Average:')\n",
    "    dev_probas[f'dev_RA_{loop}'] = average(dev_probas.apply(lambda col: rankdata(col) / len(col)))\n",
    "    ts_probas[f'ts_RA_{loop}'] = average(ts_probas.apply(lambda col: rankdata(col) / len(col)))\n",
    "    tu_probas[f'tu_RA_{loop}'] = average(tu_probas.apply(lambda col: rankdata(col) / len(col)))\n",
    "    print(f\"AUROC: {roc_auc_score(gt.label, dev_probas[f'dev_RA_{loop}']):.4f}\")\n",
    "    print(f\"Accuracy: {acc_from_roc(gt.label, dev_probas[f'dev_RA_{loop}'])[0]:.4f}\")\n",
    "    print('\\n' + '-' * 50)\n",
    "    \n",
    "    # Calculate Delta & increment loop\n",
    "    delta = abs(score - last_score)\n",
    "    last_score = score\n",
    "\n",
    "    loop += 1\n",
    "\n",
    "    print(\"Currently at {} after {} loops.\".format(last_score, loop))\n",
    "\n",
    "dev_best = dev_probas[f'dev_SX_{loop-1}']\n",
    "ts_best = ts_probas[f'ts_SX_{loop-1}']\n",
    "tu_best = tu_probas[f'tu_SX_{loop-1}']\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-campaign",
   "metadata": {},
   "source": [
    "## Dump Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "desirable-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'OVU2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prime-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Get accuracy thresholds & optimize (This does not add value to the roc auc, but just to also have an acc score)\n",
    "acc, threshold = acc_from_roc(gt.label, dev_best)\n",
    "\n",
    "# As Simplex at some point simply weighs the highest of all - lets take sx as the final prediction after x loops\n",
    "ts_labels = ts_best.apply(lambda x: 1 if x > threshold else 0)\n",
    "ts_out = pd.DataFrame({'id': ts_idx, 'proba': ts_best, 'label': ts_labels})\n",
    "tu_labels = tu_best.apply(lambda x: 1 if x > threshold else 0)\n",
    "tu_out = pd.DataFrame({'id': tu_idx, 'proba': tu_best, 'label': tu_labels})\n",
    "ts_out.to_csv(os.path.join(path, f\"final/FIN_test_seen_{experiment}_{loop}.csv\"), index=False)\n",
    "tu_out.to_csv(os.path.join(path, f\"final/FIN_test_unseen_{experiment}_{loop}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "living-young",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7138867996991567"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-export",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
